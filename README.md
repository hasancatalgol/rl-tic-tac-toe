# Tic-Tac-Toe (Pygame + Minimax with Alphaâ€“Beta, printed metrics)

![preview](docs/gameplay.png)

A minimalist Tic-Tac-Toe with a clean Pygame UI and a **perfect-play AI** powered by **minimax** + **alphaâ€“beta pruning**.  
The AI prints search metrics (nodes, leaves, cutoffs, Î±/Î² window) to the console at every computer turn.

---

## Features

- ðŸŽ® Pygame UI (gradient tiles, bold grid, crisp anti-aliased Oâ€™s)
- ðŸ§  Minimax + alphaâ€“beta pruning (optimal play)
- ðŸ“Š Console metrics per root move:
  - nodes visited, terminal leaves, cutoffs (prunes), Î±/Î² window updates
- ðŸ”§ Easy to tweak visuals via constants

---

## Getting Started

### Requirements

Create Virtual Environment:

    uv init

Install:

    uv add pygame

Run:

    uv run main.py

### Controls
- **Left-click** a square to place **O**.
- **R** â€“ restart game
- **ESC** / close window â€“ quit

---

## How the Board Is Represented

The board is a dict keyed by positions **1..9**:

    1 | 2 | 3
    --+---+--
    4 | 5 | 6
    --+---+--
    7 | 8 | 9

- Empty cells contain `' '`
- Player is **'O'**, computer is **'X'**

---

## Algorithms

### Minimax (with depth-aware scoring)
At any position, minimax explores the game tree to pick the move that maximizes the computerâ€™s outcome assuming the opponent plays optimally.

**Terminal scoring** (from Xâ€™s perspective):

- X wins  â†’ `REWARD - depth` (win sooner = slightly better)
- O wins  â†’ `-REWARD + depth` (loss later = slightly less bad)
- Draw    â†’ `0`

In this project, `REWARD = 10`.  
Because Tic-Tac-Toe is small, this exact evaluation (no heuristics) is enough for perfect play.

### Alphaâ€“Beta Pruning
Alphaâ€“beta maintains two bounds during depth-first search:

- **Î± (alpha)** = best score found so far along the **maximizer** (X) path  
- **Î² (beta)**  = best score found so far along the **minimizer** (O) path

Whenever `Î± â‰¥ Î²`, the branch cannot influence the final decision and is **pruned** (cut off), saving work while keeping the result exact.

This project logs, per root move:

- nodes expanded in that subtree  
- terminal leaves evaluated  
- number of cutoffs (prunes)  
- Î±/Î² window tightening

### Sample console output (illustrative)

    === Computer turn (X) ===
    Board:
    X| | 
    -+-+-
     |O| 
    -+-+-
     | | 

    Remaining action space (legal moves): [3, 4, 6, 7, 8, 9]
      Move 3: score=  0 | nodes=  28 leaves=  10 cutoffs=  4 | Î±Î² -inf,+inf ->   0,+inf
      Move 4: score=  0 | nodes=  26 leaves=   9 cutoffs=  3 | Î±Î²   0,+inf ->   0,+inf
      ...
    Best choice: move 3 with score 0
    Totals: nodes=150, leaves=55, cutoffs=20, max_depth=9, time=3.21 ms
    === End of evaluation ===

---

## Code Map

- **`TicTacToe`**
  - `place(player, position)` â€“ mutates board if cell is free
  - `is_winning(player)` / `is_draw()` â€“ terminal checks
  - `free_positions()` â€“ list of empty cells
  - `best_move(verbose=True)` â€“ evaluates each legal root move, prints metrics, returns the best move
  - `_minimax(depth, alpha, beta, is_maximizer, stats)` â€“ recursive minimax with alphaâ€“beta and stats

- **UI helpers**
  - Gradient tile rendering (`make_horizontal_gradient_surface`, `draw_pretty_board`)
  - Crisp **O** via supersampled/AA sprite (`make_ring_sprite`)
  - `draw_marks` â€“ draws X and O
  - Input â†’ board cell mapping

---

## Customization

All visuals live in constants near the top of the UI section:

```python
GRID_SIZE = 600
INFO_HEIGHT = 80
LINE_WIDTH = 10
MARK_WIDTH = 12
TILE_MARGIN = 14
PADDING = 38

PURPLE = (123, 47, 247)
PINK   = (241, 7, 163)
INK    = (15, 15, 15)
